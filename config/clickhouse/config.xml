<?xml version="1.0"?>
<clickhouse>
    <!-- Logging -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
    </logger>

    <!-- Network -->
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>
    <mysql_port>9004</mysql_port>
    <postgresql_port>9005</postgresql_port>
    <interserver_http_port>9009</interserver_http_port>
    
    <listen_host>::</listen_host>
    <listen_host>0.0.0.0</listen_host>
    
    <!-- Security -->
    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>
    
    <!-- Memory -->
    <max_server_memory_usage>0</max_server_memory_usage>
    <max_server_memory_usage_to_ram_ratio>0.9</max_server_memory_usage_to_ram_ratio>
    <max_memory_usage>10000000000</max_memory_usage>
    <max_bytes_before_external_group_by>20000000000</max_bytes_before_external_group_by>
    <max_bytes_before_external_sort>20000000000</max_bytes_before_external_sort>
    
    <!-- Storage -->
    <path>/var/lib/clickhouse/</path>
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
    <access_control_path>/var/lib/clickhouse/access/</access_control_path>
    
    <!-- Users configuration -->
    <users_config>users.xml</users_config>
    
    <!-- Default profile settings -->
    <default_profile>default</default_profile>
    <default_database>typosentinel_analytics</default_database>
    
    <!-- Timezone -->
    <timezone>UTC</timezone>
    
    <!-- Compression -->
    <compression>
        <case>
            <method>lz4</method>
        </case>
    </compression>
    
    <!-- Query log -->
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_log>
    
    <!-- Query thread log -->
    <query_thread_log>
        <database>system</database>
        <table>query_thread_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_thread_log>
    
    <!-- Part log -->
    <part_log>
        <database>system</database>
        <table>part_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </part_log>
    
    <!-- Metric log -->
    <metric_log>
        <database>system</database>
        <table>metric_log</table>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
    </metric_log>
    
    <!-- Distributed DDL -->
    <distributed_ddl>
        <path>/clickhouse/task_queue/ddl</path>
    </distributed_ddl>
    
    <!-- Format schemas -->
    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
    
    <!-- Dictionaries -->
    <dictionaries_config>*_dictionary.xml</dictionaries_config>
    
    <!-- Performance settings for Typosentinel analytics -->
    <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        <parts_to_delay_insert>150</parts_to_delay_insert>
        <parts_to_throw_insert>300</parts_to_throw_insert>
        <max_delay_to_insert>1</max_delay_to_insert>
        <max_parts_in_total>100000</max_parts_in_total>
        <replicated_deduplication_window>100</replicated_deduplication_window>
        <replicated_deduplication_window_seconds>604800</replicated_deduplication_window_seconds>
        <old_parts_lifetime>480</old_parts_lifetime>
        <max_bytes_to_merge_at_max_space_in_pool>161061273600</max_bytes_to_merge_at_max_space_in_pool>
        <max_bytes_to_merge_at_min_space_in_pool>1048576</max_bytes_to_merge_at_min_space_in_pool>
        <merge_max_block_size>8192</merge_max_block_size>
    </merge_tree>
    
    <!-- Background processing -->
    <background_pool_size>16</background_pool_size>
    <background_merges_mutations_concurrency_ratio>2</background_merges_mutations_concurrency_ratio>
    <background_schedule_pool_size>16</background_schedule_pool_size>
    <background_fetches_pool_size>8</background_fetches_pool_size>
    <background_move_pool_size>8</background_move_pool_size>
    <background_common_pool_size>8</background_common_pool_size>
    
    <!-- Kafka integration for real-time data ingestion -->
    <kafka>
        <auto_offset_reset>smallest</auto_offset_reset>
        <kafka_commit_every_batch>0</kafka_commit_every_batch>
        <kafka_max_block_size>1048576</kafka_max_block_size>
    </kafka>
    
    <!-- HTTP interface settings -->
    <http_server_default_response><![CDATA[<html ng-app="SMI2"><head><base href="http://ui.tabix.io/"></head><body><div ui-view="" class="content-ui"></div><script src="http://loader.tabix.io/master.js"></script></body></html>]]></http_server_default_response>
    
    <!-- Prometheus metrics -->
    <prometheus>
        <endpoint>/metrics</endpoint>
        <port>9363</port>
        <metrics>true</metrics>
        <events>true</events>
        <asynchronous_metrics>true</asynchronous_metrics>
    </prometheus>
    
    <!-- OpenTelemetry -->
    <opentelemetry>
        <trace_processors>
            <batch>
                <endpoint>http://jaeger:14268/api/traces</endpoint>
            </batch>
        </trace_processors>
    </opentelemetry>
    
    <!-- Session log -->
    <session_log>
        <database>system</database>
        <table>session_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </session_log>
    
    <!-- Text log -->
    <text_log>
        <database>system</database>
        <table>text_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <level>information</level>
    </text_log>
    
    <!-- Crash log -->
    <crash_log>
        <database>system</database>
        <table>crash_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <flush_interval_milliseconds>1000</flush_interval_milliseconds>
    </crash_log>
    
    <!-- Custom settings for Typosentinel -->
    <profiles>
        <typosentinel_analytics>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
            <max_execution_time>300</max_execution_time>
            <max_query_size>1000000</max_query_size>
            <max_ast_depth>1000</max_ast_depth>
            <max_ast_elements>100000</max_ast_elements>
            <max_expanded_ast_elements>500000</max_expanded_ast_elements>
            <readonly>0</readonly>
            <allow_ddl>1</allow_ddl>
            <allow_introspection_functions>1</allow_introspection_functions>
        </typosentinel_analytics>
    </profiles>
    
    <!-- Quotas -->
    <quotas>
        <typosentinel_quota>
            <interval>
                <duration>3600</duration>
                <queries>1000</queries>
                <errors>100</errors>
                <result_rows>1000000000</result_rows>
                <read_rows>1000000000</read_rows>
                <execution_time>3600</execution_time>
            </interval>
        </typosentinel_quota>
    </quotas>
    
    <!-- Resharding -->
    <remote_servers>
        <typosentinel_cluster>
            <shard>
                <replica>
                    <host>clickhouse</host>
                    <port>9000</port>
                </replica>
            </shard>
        </typosentinel_cluster>
    </remote_servers>
    
    <!-- Macros -->
    <macros>
        <cluster>typosentinel_cluster</cluster>
        <shard>01</shard>
        <replica>replica_1</replica>
    </macros>
    
    <!-- Built-in dictionaries -->
    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
    
    <!-- Asynchronous insert settings -->
    <asynchronous_insert_log>
        <database>system</database>
        <table>asynchronous_insert_log</table>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </asynchronous_insert_log>
    
    <!-- Custom storage policies for different data types -->
    <storage_configuration>
        <disks>
            <default>
                <path>/var/lib/clickhouse/</path>
            </default>
            <hot>
                <path>/var/lib/clickhouse/hot/</path>
            </hot>
            <cold>
                <path>/var/lib/clickhouse/cold/</path>
            </cold>
        </disks>
        <policies>
            <typosentinel_policy>
                <volumes>
                    <hot>
                        <disk>hot</disk>
                        <max_data_part_size_bytes>1073741824</max_data_part_size_bytes>
                    </hot>
                    <cold>
                        <disk>cold</disk>
                    </cold>
                </volumes>
                <move_factor>0.2</move_factor>
            </typosentinel_policy>
        </policies>
    </storage_configuration>
</clickhouse>