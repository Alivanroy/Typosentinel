package vulnerability

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/Alivanroy/Typosentinel/pkg/types"
)

// Manager coordinates multiple vulnerability databases
type Manager struct {
	databases   map[string]types.VulnerabilityDatabase
	config      *ManagerConfig
	mu          sync.RWMutex
	refreshStop chan struct{}
}

// ManagerConfig contains configuration for the vulnerability manager
type ManagerConfig struct {
	Databases       []types.VulnerabilityDatabaseConfig `json:"databases"`
	ParallelQueries bool                                `json:"parallel_queries"`
	Timeout         time.Duration                       `json:"timeout"`
	CacheEnabled    bool                                `json:"cache_enabled"`
	CacheTTL        time.Duration                       `json:"cache_ttl"`
	Priority        []string                            `json:"priority"` // Database priority order
	MergeResults    bool                                `json:"merge_results"`
	DeduplicateByID bool                                `json:"deduplicate_by_id"`
	RefreshInterval time.Duration                       `json:"refresh_interval"`
}

// NewManager creates a new vulnerability database manager
func NewManager(config *ManagerConfig) *Manager {
	if config == nil {
		config = &ManagerConfig{
			ParallelQueries: true,
			Timeout:         30 * time.Second,
			CacheEnabled:    true,
			CacheTTL:        1 * time.Hour,
			MergeResults:    true,
			DeduplicateByID: true,
			Priority:        []string{"osv", "github", "nvd"},
		}
	}

	m := &Manager{
		databases:   make(map[string]types.VulnerabilityDatabase),
		config:      config,
		refreshStop: make(chan struct{}),
	}

	// Initialize databases based on configuration
	m.initializeDatabases()

	// Start scheduler for database updates if configured
	if m.config.RefreshInterval > 0 {
		go m.startScheduler()
	}

	return m
}

// initializeDatabases initializes vulnerability databases based on configuration
func (m *Manager) initializeDatabases() {
	for _, dbConfig := range m.config.Databases {
		if !dbConfig.Enabled {
			continue
		}

		switch dbConfig.Type {
		case "osv":
			db := NewOSVDatabase()
			m.databases["osv"] = db
		case "github":
			db := NewGitHubAdvisoryDatabase(dbConfig.APIKey)
			m.databases["github"] = db
		case "nvd":
			// Initialize existing NVD database
			db := NewCVEDatabase()
			m.databases["nvd"] = db
		}
	}
}

// AddDatabase adds a vulnerability database to the manager
func (m *Manager) AddDatabase(name string, db types.VulnerabilityDatabase) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.databases[name] = db
}

// RemoveDatabase removes a vulnerability database from the manager
func (m *Manager) RemoveDatabase(name string) {
	m.mu.Lock()
	defer m.mu.Unlock()
	delete(m.databases, name)
}

// CheckVulnerabilities checks for vulnerabilities across all configured databases
func (m *Manager) CheckVulnerabilities(pkg *types.Package) ([]*types.Vulnerability, error) {
	m.mu.RLock()
	databases := make(map[string]types.VulnerabilityDatabase)
	for name, db := range m.databases {
		databases[name] = db
	}
	m.mu.RUnlock()

	if len(databases) == 0 {
		return nil, fmt.Errorf("no vulnerability databases configured")
	}

	ctx, cancel := context.WithTimeout(context.Background(), m.config.Timeout)
	defer cancel()

	if m.config.ParallelQueries {
		return m.checkVulnerabilitiesParallel(ctx, pkg, databases)
	}

	return m.checkVulnerabilitiesSequential(ctx, pkg, databases)
}

// checkVulnerabilitiesParallel checks vulnerabilities in parallel across databases
func (m *Manager) checkVulnerabilitiesParallel(ctx context.Context, pkg *types.Package, databases map[string]types.VulnerabilityDatabase) ([]*types.Vulnerability, error) {
	type result struct {
		name  string
		vulns []*types.Vulnerability
		err   error
	}

	resultChan := make(chan result, len(databases))
	var wg sync.WaitGroup

	// Query all databases in parallel
	for name, db := range databases {
		wg.Add(1)
		go func(dbName string, database types.VulnerabilityDatabase) {
			defer wg.Done()
			vulns, err := database.CheckVulnerabilities(pkg)
			resultChan <- result{name: dbName, vulns: vulns, err: err}
		}(name, db)
	}

	// Wait for all queries to complete
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// Collect results
	allVulns := make([]*types.Vulnerability, 0)
	errors := make([]error, 0)

	for res := range resultChan {
		if res.err != nil {
			errors = append(errors, fmt.Errorf("%s: %w", res.name, res.err))
			continue
		}

		// Add source information to vulnerabilities
		for _, vuln := range res.vulns {
			if vuln.Source == "" {
				vuln.Source = res.name
			}
		}

		allVulns = append(allVulns, res.vulns...)
	}

	// If all databases failed, return the errors
	if len(allVulns) == 0 && len(errors) > 0 {
		return nil, fmt.Errorf("all vulnerability databases failed: %v", errors)
	}

	if m.config.MergeResults {
		return m.mergeAndDeduplicateVulnerabilities(allVulns), nil
	}

	return allVulns, nil
}

// checkVulnerabilitiesSequential checks vulnerabilities sequentially based on priority
func (m *Manager) checkVulnerabilitiesSequential(ctx context.Context, pkg *types.Package, databases map[string]types.VulnerabilityDatabase) ([]*types.Vulnerability, error) {
	allVulns := make([]*types.Vulnerability, 0)
	errors := make([]error, 0)

	// Use priority order if configured
	order := m.config.Priority
	if len(order) == 0 {
		// Default order if no priority specified
		for name := range databases {
			order = append(order, name)
		}
	}

	for _, dbName := range order {
		db, exists := databases[dbName]
		if !exists {
			continue
		}

		vulns, err := db.CheckVulnerabilities(pkg)
		if err != nil {
			errors = append(errors, fmt.Errorf("%s: %w", dbName, err))
			continue
		}

		// Add source information
		for _, vuln := range vulns {
			if vuln.Source == "" {
				vuln.Source = dbName
			}
		}

		allVulns = append(allVulns, vulns...)
	}

	// Check remaining databases not in priority list
	for dbName, db := range databases {
		found := false
		for _, priorityName := range order {
			if dbName == priorityName {
				found = true
				break
			}
		}
		if found {
			continue
		}

		vulns, err := db.CheckVulnerabilities(pkg)
		if err != nil {
			errors = append(errors, fmt.Errorf("%s: %w", dbName, err))
			continue
		}

		for _, vuln := range vulns {
			if vuln.Source == "" {
				vuln.Source = dbName
			}
		}

		allVulns = append(allVulns, vulns...)
	}

	if len(allVulns) == 0 && len(errors) > 0 {
		return nil, fmt.Errorf("all vulnerability databases failed: %v", errors)
	}

	if m.config.MergeResults {
		return m.mergeAndDeduplicateVulnerabilities(allVulns), nil
	}

	return allVulns, nil
}

// GetVulnerabilityByID retrieves a vulnerability by ID from the first available database
func (m *Manager) GetVulnerabilityByID(id string) (*types.Vulnerability, error) {
	m.mu.RLock()
	databases := make(map[string]types.VulnerabilityDatabase)
	for name, db := range m.databases {
		databases[name] = db
	}
	m.mu.RUnlock()

	if len(databases) == 0 {
		return nil, fmt.Errorf("no vulnerability databases configured")
	}

	// Try databases in priority order
	for _, dbName := range m.config.Priority {
		db, exists := databases[dbName]
		if !exists {
			continue
		}

		vuln, err := db.GetVulnerabilityByID(id)
		if err == nil && vuln != nil {
			if vuln.Source == "" {
				vuln.Source = dbName
			}
			return vuln, nil
		}
	}

	// Try remaining databases
	for dbName, db := range databases {
		found := false
		for _, priorityName := range m.config.Priority {
			if dbName == priorityName {
				found = true
				break
			}
		}
		if found {
			continue
		}

		vuln, err := db.GetVulnerabilityByID(id)
		if err == nil && vuln != nil {
			if vuln.Source == "" {
				vuln.Source = dbName
			}
			return vuln, nil
		}
	}

	return nil, fmt.Errorf("vulnerability %s not found in any database", id)
}

// SearchVulnerabilities searches for vulnerabilities across all databases
func (m *Manager) SearchVulnerabilities(query string) ([]*types.Vulnerability, error) {
	m.mu.RLock()
	databases := make(map[string]types.VulnerabilityDatabase)
	for name, db := range m.databases {
		databases[name] = db
	}
	m.mu.RUnlock()

	if len(databases) == 0 {
		return nil, fmt.Errorf("no vulnerability databases configured")
	}

	allVulns := make([]*types.Vulnerability, 0)

	for dbName, db := range databases {
		vulns, err := db.SearchVulnerabilities(query)
		if err != nil {
			// Log error but continue with other databases
			continue
		}

		for _, vuln := range vulns {
			if vuln.Source == "" {
				vuln.Source = dbName
			}
		}

		allVulns = append(allVulns, vulns...)
	}

	if m.config.MergeResults {
		return m.mergeAndDeduplicateVulnerabilities(allVulns), nil
	}

	return allVulns, nil
}

// mergeAndDeduplicateVulnerabilities merges and deduplicates vulnerabilities
func (m *Manager) mergeAndDeduplicateVulnerabilities(vulns []*types.Vulnerability) []*types.Vulnerability {
	if !m.config.DeduplicateByID {
		return vulns
	}

	seen := make(map[string]*types.Vulnerability)
	result := make([]*types.Vulnerability, 0)

	for _, vuln := range vulns {
		key := vuln.ID
		if key == "" {
			// If no ID, use CVE or title as fallback
			if vuln.CVE != "" {
				key = vuln.CVE
			} else {
				key = vuln.Title
			}
		}

		if existing, exists := seen[key]; exists {
			// Merge vulnerability information
			m.mergeVulnerabilityData(existing, vuln)
		} else {
			seen[key] = vuln
			result = append(result, vuln)
		}
	}

	return result
}

// mergeVulnerabilityData merges data from two vulnerability records
func (m *Manager) mergeVulnerabilityData(existing, new *types.Vulnerability) {
	// Merge aliases
	for _, alias := range new.Aliases {
		found := false
		for _, existingAlias := range existing.Aliases {
			if alias == existingAlias {
				found = true
				break
			}
		}
		if !found {
			existing.Aliases = append(existing.Aliases, alias)
		}
	}

	// Merge references
	for _, ref := range new.References {
		found := false
		for _, existingRef := range existing.References {
			if ref == existingRef {
				found = true
				break
			}
		}
		if !found {
			existing.References = append(existing.References, ref)
		}
	}

	// Merge affected packages
	for _, pkg := range new.AffectedPackages {
		found := false
		for _, existingPkg := range existing.AffectedPackages {
			if pkg.Name == existingPkg.Name && pkg.Ecosystem == existingPkg.Ecosystem {
				found = true
				break
			}
		}
		if !found {
			existing.AffectedPackages = append(existing.AffectedPackages, pkg)
		}
	}

	// Use higher severity if available
	if new.Severity > existing.Severity {
		existing.Severity = new.Severity
	}

	// Merge metadata
	if existing.Metadata == nil {
		existing.Metadata = make(map[string]interface{})
	}
	for key, value := range new.Metadata {
		existing.Metadata[key] = value
	}
}

// GetDatabaseNames returns the names of all configured databases
func (m *Manager) GetDatabaseNames() []string {
	m.mu.RLock()
	defer m.mu.RUnlock()

	names := make([]string, 0, len(m.databases))
	for name := range m.databases {
		names = append(names, name)
	}
	return names
}

// GetDatabaseCount returns the number of configured databases
func (m *Manager) GetDatabaseCount() int {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return len(m.databases)
}

// UpdateConfiguration updates the manager configuration
func (m *Manager) UpdateConfiguration(config *ManagerConfig) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.config = config
	m.initializeDatabases()
}
func (m *Manager) startScheduler() {
	ticker := time.NewTicker(m.config.RefreshInterval)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			m.mu.RLock()
			for _, db := range m.databases {
				type updater interface{ Update(context.Context) error }
				if u, ok := db.(updater); ok {
					_ = u.Update(context.Background())
				}
			}
			m.mu.RUnlock()
		case <-m.refreshStop:
			return
		}
	}
}
