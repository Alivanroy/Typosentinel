#!/usr/bin/env python3
"""
Multi-Ecosystem Malware Analysis Tool
Analyzes packages from npm, PyPI, and other ecosystems for malicious patterns
"""

import os
import sys
import ast
import base64
import re
import tarfile
import zipfile
import requests
import json
import shutil
import tempfile
import argparse
import subprocess
from urllib.parse import urlparse
from pathlib import Path

class MultiEcosystemMalwareAnalyzer:
    def __init__(self):
        self.temp_dir = None
        self.findings = []
        
        # Suspicious patterns to detect
        self.patterns = {
            'obfuscated_code': [
                r'exec\s*\(\s*base64\.b64decode',
                r'eval\s*\(\s*base64\.b64decode',
                r'compile\s*\(\s*base64\.b64decode',
                r'__import__\s*\(\s*["\']base64["\']',
                r'exec\s*\(\s*compile\s*\(',
                r'eval\s*\(\s*compile\s*\(',
                r'atob\s*\(',  # JavaScript base64 decode
                r'btoa\s*\(',  # JavaScript base64 encode
                r'Function\s*\(\s*["\'].*["\'].*\)',  # Dynamic function creation
            ],
            'data_exfiltration': [
                r'discord\.com/api/webhooks',
                r'telegram\.org',
                r'pastebin\.com',
                r'hastebin\.com',
                r'paste\.ee',
                r'requests\.post.*webhook',
                r'urllib.*webhook',
                r'http.*://.*\.ngrok\.io',
                r'fetch\s*\(\s*["\'].*webhook.*["\']',  # JavaScript fetch
                r'XMLHttpRequest',  # JavaScript AJAX
            ],
            'crypto_mining': [
                r'stratum\+tcp://',
                r'xmrig',
                r'minergate',
                r'cryptonight',
                r'monero',
                r'mining.*pool',
                r'hashrate',
                r'coinhive',
            ],
            'credential_theft': [
                r'\.aws/credentials',
                r'\.ssh/id_rsa',
                r'\.docker/config\.json',
                r'password.*=.*input',
                r'getpass\.getpass',
                r'keyring\.get_password',
                r'process\.env\..*PASSWORD',  # Environment variables
                r'localStorage\.getItem',  # Browser storage
            ],
            'system_access': [
                r'os\.system\s*\(',
                r'subprocess\.call',
                r'subprocess\.run',
                r'subprocess\.Popen',
                r'os\.popen',
                r'commands\.getoutput',
                r'child_process\.exec',  # Node.js
                r'require\s*\(\s*["\']child_process["\']',
            ],
            'network_activity': [
                r'socket\.socket',
                r'urllib\.request',
                r'requests\.get',
                r'requests\.post',
                r'http\.client',
                r'ftplib\.FTP',
                r'require\s*\(\s*["\']http["\']',  # Node.js
                r'require\s*\(\s*["\']https["\']',
                r'require\s*\(\s*["\']net["\']',
            ]
        }

    def download_npm_package(self, package_name, version=None):
        """Download package from npm registry"""
        try:
            print(f"üì¶ Downloading npm package: {package_name}")
            
            # Get package info from npm registry
            if version:
                url = f"https://registry.npmjs.org/{package_name}/{version}"
            else:
                url = f"https://registry.npmjs.org/{package_name}/latest"
            
            response = requests.get(url)
            response.raise_for_status()
            
            package_info = response.json()
            
            # Get tarball URL
            if 'dist' in package_info and 'tarball' in package_info['dist']:
                tarball_url = package_info['dist']['tarball']
            else:
                print(f"‚ùå No tarball found for {package_name}")
                return None
            
            # Download the package
            print(f"‚¨áÔ∏è  Downloading: {tarball_url}")
            
            response = requests.get(tarball_url)
            response.raise_for_status()
            
            # Save to temp directory
            if not self.temp_dir:
                self.temp_dir = tempfile.mkdtemp(prefix='malware_analysis_')
            
            filename = f"{package_name.replace('/', '_')}-{package_info.get('version', 'latest')}.tgz"
            package_path = os.path.join(self.temp_dir, filename)
            
            with open(package_path, 'wb') as f:
                f.write(response.content)
            
            print(f"‚úÖ Downloaded: {package_path}")
            return package_path
            
        except Exception as e:
            print(f"‚ùå Error downloading npm package {package_name}: {e}")
            return None

    def download_pypi_package(self, package_name, version=None):
        """Download package from PyPI"""
        try:
            print(f"üì¶ Downloading PyPI package: {package_name}")
            
            # Get package info from PyPI
            if version:
                url = f"https://pypi.org/pypi/{package_name}/{version}/json"
            else:
                url = f"https://pypi.org/pypi/{package_name}/json"
            
            response = requests.get(url)
            response.raise_for_status()
            
            package_info = response.json()
            
            # Find source distribution
            files = package_info['urls']
            source_dist = None
            
            for file_info in files:
                if file_info['packagetype'] == 'sdist':
                    source_dist = file_info
                    break
            
            if not source_dist:
                print(f"‚ùå No source distribution found for {package_name}")
                return None
            
            # Download the package
            download_url = source_dist['url']
            filename = source_dist['filename']
            
            print(f"‚¨áÔ∏è  Downloading: {filename}")
            
            response = requests.get(download_url)
            response.raise_for_status()
            
            # Save to temp directory
            if not self.temp_dir:
                self.temp_dir = tempfile.mkdtemp(prefix='malware_analysis_')
            
            package_path = os.path.join(self.temp_dir, filename)
            with open(package_path, 'wb') as f:
                f.write(response.content)
            
            print(f"‚úÖ Downloaded: {package_path}")
            return package_path
            
        except Exception as e:
            print(f"‚ùå Error downloading PyPI package {package_name}: {e}")
            return None

    def download_package(self, package_name, ecosystem, version=None):
        """Download package based on ecosystem"""
        if ecosystem == 'npm':
            return self.download_npm_package(package_name, version)
        elif ecosystem == 'pypi' or ecosystem == 'python':
            return self.download_pypi_package(package_name, version)
        else:
            print(f"‚ùå Unsupported ecosystem: {ecosystem}")
            return None

    def extract_package(self, package_path):
        """Extract package contents"""
        try:
            extract_dir = os.path.join(self.temp_dir, 'extracted')
            os.makedirs(extract_dir, exist_ok=True)
            
            print(f"üìÇ Extracting package: {os.path.basename(package_path)}")
            
            if package_path.endswith('.tar.gz') or package_path.endswith('.tgz'):
                with tarfile.open(package_path, 'r:gz') as tar:
                    tar.extractall(extract_dir)
            elif package_path.endswith('.zip'):
                with zipfile.ZipFile(package_path, 'r') as zip_file:
                    zip_file.extractall(extract_dir)
            else:
                print(f"‚ùå Unsupported package format: {package_path}")
                return None
            
            print(f"‚úÖ Extracted to: {extract_dir}")
            return extract_dir
            
        except Exception as e:
            print(f"‚ùå Error extracting package: {e}")
            return None

    def analyze_file(self, filepath):
        """Analyze a single file for malicious patterns"""
        file_findings = []
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Check each pattern category
            for category, patterns in self.patterns.items():
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                    for match in matches:
                        # Get line number
                        line_num = content[:match.start()].count('\n') + 1
                        
                        file_findings.append({
                            'file': filepath,
                            'category': category,
                            'pattern': pattern,
                            'match': match.group(),
                            'line': line_num,
                            'severity': self.get_severity(category)
                        })
            
            # Additional checks for Python files
            if filepath.endswith('.py'):
                file_findings.extend(self.analyze_python_ast(filepath, content))
            
            # Additional checks for JavaScript files
            if filepath.endswith('.js') or filepath.endswith('.ts'):
                file_findings.extend(self.analyze_javascript_patterns(filepath, content))
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Error analyzing file {filepath}: {e}")
        
        return file_findings

    def analyze_python_ast(self, filepath, content):
        """Analyze Python AST for suspicious constructs"""
        findings = []
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                # Check for dynamic imports
                if isinstance(node, ast.Call):
                    if (isinstance(node.func, ast.Name) and 
                        node.func.id == '__import__' and 
                        len(node.args) > 0):
                        findings.append({
                            'file': filepath,
                            'category': 'dynamic_import',
                            'pattern': 'AST: __import__ call',
                            'match': f"__import__({ast.unparse(node.args[0]) if hasattr(ast, 'unparse') else 'dynamic'})",
                            'line': node.lineno,
                            'severity': 'MEDIUM'
                        })
                
                # Check for exec/eval calls
                if (isinstance(node, ast.Call) and 
                    isinstance(node.func, ast.Name) and 
                    node.func.id in ['exec', 'eval']):
                    findings.append({
                        'file': filepath,
                        'category': 'code_execution',
                        'pattern': f'AST: {node.func.id} call',
                        'match': f"{node.func.id}(...)",
                        'line': node.lineno,
                        'severity': 'HIGH'
                    })
                        
        except SyntaxError:
            # File might not be valid Python
            pass
        except Exception as e:
            print(f"‚ö†Ô∏è  AST analysis error for {filepath}: {e}")
        
        return findings

    def analyze_javascript_patterns(self, filepath, content):
        """Analyze JavaScript files for suspicious patterns"""
        findings = []
        
        # JavaScript-specific suspicious patterns
        js_patterns = {
            'eval_usage': r'eval\s*\(',
            'function_constructor': r'new\s+Function\s*\(',
            'document_write': r'document\.write\s*\(',
            'settimeout_string': r'setTimeout\s*\(\s*["\']',
            'setinterval_string': r'setInterval\s*\(\s*["\']',
            'crypto_require': r'require\s*\(\s*["\']crypto["\']',
            'fs_require': r'require\s*\(\s*["\']fs["\']',
            'process_env': r'process\.env\.',
        }
        
        for pattern_name, pattern in js_patterns.items():
            matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                
                findings.append({
                    'file': filepath,
                    'category': 'javascript_suspicious',
                    'pattern': f'JS: {pattern_name}',
                    'match': match.group(),
                    'line': line_num,
                    'severity': 'MEDIUM'
                })
        
        return findings

    def get_severity(self, category):
        """Get severity level for a category"""
        severity_map = {
            'obfuscated_code': 'CRITICAL',
            'data_exfiltration': 'CRITICAL',
            'crypto_mining': 'HIGH',
            'credential_theft': 'HIGH',
            'system_access': 'MEDIUM',
            'network_activity': 'LOW',
            'javascript_suspicious': 'MEDIUM',
            'dynamic_import': 'MEDIUM',
            'code_execution': 'HIGH'
        }
        return severity_map.get(category, 'MEDIUM')

    def analyze_package_contents(self, extract_dir):
        """Deep analysis of package contents"""
        print(f"üîç Analyzing package contents...")
        
        all_findings = []
        file_count = 0
        
        # Walk through all files
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                filepath = os.path.join(root, file)
                file_count += 1
                
                # Analyze text files
                extensions = ['.py', '.js', '.ts', '.txt', '.md', '.rst', '.cfg', '.ini', 
                             '.json', '.yaml', '.yml', '.sh', '.bat', '.ps1']
                if any(filepath.endswith(ext) for ext in extensions):
                    findings = self.analyze_file(filepath)
                    all_findings.extend(findings)
        
        print(f"üìä Analyzed {file_count} files")
        return all_findings

    def generate_report(self, package_name, ecosystem, findings):
        """Generate analysis report"""
        print(f"\nüîç MALWARE ANALYSIS REPORT: {package_name} ({ecosystem})")
        print("=" * 70)
        
        if not findings:
            print("‚úÖ No suspicious patterns detected")
            return
        
        # Group findings by severity
        severity_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0}
        category_counts = {}
        
        for finding in findings:
            severity = finding['severity']
            category = finding['category']
            
            severity_counts[severity] += 1
            category_counts[category] = category_counts.get(category, 0) + 1
        
        # Print summary
        print(f"üö® TOTAL FINDINGS: {len(findings)}")
        for severity, count in severity_counts.items():
            if count > 0:
                emoji = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[severity]
                print(f"{emoji} {severity}: {count}")
        
        print(f"\nüìã CATEGORIES:")
        for category, count in sorted(category_counts.items()):
            print(f"  ‚Ä¢ {category.replace('_', ' ').title()}: {count}")
        
        # Print top 10 most critical findings
        critical_findings = [f for f in findings if f['severity'] in ['CRITICAL', 'HIGH']]
        if critical_findings:
            print(f"\nüö® TOP CRITICAL/HIGH FINDINGS (showing first 10):")
            for i, finding in enumerate(critical_findings[:10], 1):
                severity_emoji = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MEDIUM': 'üü°', 'LOW': 'üü¢'}[finding['severity']]
                print(f"\n{i}. {severity_emoji} {finding['severity']} - {finding['category'].replace('_', ' ').title()}")
                print(f"   File: {os.path.basename(finding['file'])}")
                print(f"   Line: {finding['line']}")
                print(f"   Match: {finding['match'][:100]}{'...' if len(finding['match']) > 100 else ''}")

    def cleanup(self):
        """Clean up temporary files"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
            print(f"üßπ Cleaned up temporary files")

    def analyze_package(self, package_name, ecosystem, version=None):
        """Main analysis function"""
        try:
            print(f"üöÄ Starting malware analysis for: {package_name} ({ecosystem})")
            
            # Reset temp directory for each package
            self.temp_dir = None
            
            # Download package
            package_path = self.download_package(package_name, ecosystem, version)
            if not package_path:
                return False, []
            
            # Extract package
            extract_dir = self.extract_package(package_path)
            if not extract_dir:
                return False, []
            
            # Analyze contents
            findings = self.analyze_package_contents(extract_dir)
            
            # Generate report
            self.generate_report(package_name, ecosystem, findings)
            
            return True, findings
            
        except Exception as e:
            print(f"‚ùå Analysis failed: {e}")
            return False, []
        finally:
            self.cleanup()

def main():
    parser = argparse.ArgumentParser(description='Multi-Ecosystem Malware Analysis Tool')
    parser.add_argument('packages', nargs='+', help='Package names to analyze')
    parser.add_argument('--ecosystem', choices=['npm', 'pypi', 'python'], default='pypi', 
                       help='Package ecosystem (default: pypi)')
    parser.add_argument('--version', help='Specific version to analyze')
    parser.add_argument('--output', help='Output file for results (JSON format)')
    
    args = parser.parse_args()
    
    analyzer = MultiEcosystemMalwareAnalyzer()
    results = {}
    
    for package_name in args.packages:
        print(f"\n{'='*80}")
        success, findings = analyzer.analyze_package(package_name, args.ecosystem, args.version)
        results[package_name] = {
            'success': success,
            'ecosystem': args.ecosystem,
            'findings_count': len(findings),
            'critical_findings': len([f for f in findings if f['severity'] == 'CRITICAL']),
            'high_findings': len([f for f in findings if f['severity'] == 'HIGH'])
        }
    
    # Save results if output file specified
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nüíæ Results saved to: {args.output}")

if __name__ == "__main__":
    main()